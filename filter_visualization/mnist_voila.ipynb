{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 850,
     "status": "ok",
     "timestamp": 1593247266652,
     "user": {
      "displayName": "강소영",
      "photoUrl": "",
      "userId": "00381892188238952708"
     },
     "user_tz": -540
    },
    "id": "C49S_ZuVzUFL"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "akGOlWz2_g2s"
   },
   "source": [
    "# Filter Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1912,
     "status": "ok",
     "timestamp": 1593247267719,
     "user": {
      "displayName": "강소영",
      "photoUrl": "",
      "userId": "00381892188238952708"
     },
     "user_tz": -540
    },
    "id": "w5baw-g11VZU"
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1875,
     "status": "ok",
     "timestamp": 1593247267722,
     "user": {
      "displayName": "강소영",
      "photoUrl": "",
      "userId": "00381892188238952708"
     },
     "user_tz": -540
    },
    "id": "DZ5F6Gw1zqPV"
   },
   "outputs": [],
   "source": [
    "batchSize = 50\n",
    "numClass = 10\n",
    "epochs = 12\n",
    "\n",
    "img_rows, img_cols = 28, 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1867,
     "status": "ok",
     "timestamp": 1593247267723,
     "user": {
      "displayName": "강소영",
      "photoUrl": "",
      "userId": "00381892188238952708"
     },
     "user_tz": -540
    },
    "id": "UmzchqDe9BDL"
   },
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, numClass)\n",
    "y_test = keras.utils.to_categorical(y_test, numClass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('keras_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 121157,
     "status": "ok",
     "timestamp": 1593247387088,
     "user": {
      "displayName": "강소영",
      "photoUrl": "",
      "userId": "00381892188238952708"
     },
     "user_tz": -540
    },
    "id": "39wOtzVsfIlH"
   },
   "outputs": [],
   "source": [
    "def predict(idx, verbose=False):\n",
    "    img = x_test[idx]\n",
    "    label = y_test[idx]\n",
    "\n",
    "    predict = model.predict_proba(np.expand_dims(img, axis=0))\n",
    "    if verbose:\n",
    "        print(f'Index: {idx}')\n",
    "        cnt = 0\n",
    "        for i in predict[0]:\n",
    "            print('[{}] {:.2%}'.format(cnt, i))\n",
    "            cnt += 1\n",
    "        print('Predicted: ', predict[0].argmax())\n",
    "        print('Label: ', label.argmax())\n",
    "        plt.imshow(np.reshape(img, [28, 28]),interpolation='nearest', cmap='gray')\n",
    "    return (predict[0].argmax(), label.argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 121152,
     "status": "ok",
     "timestamp": 1593247387088,
     "user": {
      "displayName": "강소영",
      "photoUrl": "",
      "userId": "00381892188238952708"
     },
     "user_tz": -540
    },
    "id": "MrraMDMYvJSq"
   },
   "outputs": [],
   "source": [
    "feature_extractor = keras.Model(inputs=model.inputs, \\\n",
    "                                outputs=[layer.output for layer in model.layers])\n",
    "\n",
    "def get_hidden_layers(idx, _benchmark_=False):\n",
    "    if _benchmark_:\n",
    "        image = tf.convert_to_tensor(np.expand_dims(benchmark[idx], axis=0))\n",
    "    else:\n",
    "        image = tf.convert_to_tensor(np.expand_dims(x_test[idx], axis=0))\n",
    "    features = feature_extractor(image)\n",
    "    return features[0], features[2], features[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 121148,
     "status": "ok",
     "timestamp": 1593247387089,
     "user": {
      "displayName": "강소영",
      "photoUrl": "",
      "userId": "00381892188238952708"
     },
     "user_tz": -540
    },
    "id": "uYbSZ8bXRWOs"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def plotNNFilter(feature):\n",
    "    feature = K.eval(feature)\n",
    "    filters = feature.shape[3]  # number of filters\n",
    "    #plt.figure(1, figsize=(20,20))\n",
    "    n_columns = 5\n",
    "    n_rows = math.ceil(filters / n_columns) + 1\n",
    "\n",
    "    for i in range(filters):\n",
    "        plt.subplot(n_rows, n_columns, i+1)\n",
    "        plt.title('Filter ' + str(i))\n",
    "        plt.imshow(feature[0,:,:,i], interpolation='nearest', cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab_type": "text",
    "id": "OF7WgCS0TWY2"
   },
   "outputs": [],
   "source": [
    "### Create benchmarks\n",
    "# Take average of all the train images for each label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 121144,
     "status": "ok",
     "timestamp": 1593247387089,
     "user": {
      "displayName": "강소영",
      "photoUrl": "",
      "userId": "00381892188238952708"
     },
     "user_tz": -540
    },
    "id": "60VGLz96B9QA"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "label_class = defaultdict(list)\n",
    "for i in range(y_train.shape[0]):\n",
    "    label_class[y_train[i].argmax()].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 121121,
     "status": "ok",
     "timestamp": 1593247387090,
     "user": {
      "displayName": "강소영",
      "photoUrl": "",
      "userId": "00381892188238952708"
     },
     "user_tz": -540
    },
    "id": "NtSepKoNXpcH"
   },
   "outputs": [],
   "source": [
    "# list of x_train data(28, 28, 1) for each label\n",
    "lst = []\n",
    "for j in range(10):\n",
    "    lst.append([x_train[i] for i in label_class[j]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 121717,
     "status": "ok",
     "timestamp": 1593247387691,
     "user": {
      "displayName": "강소영",
      "photoUrl": "",
      "userId": "00381892188238952708"
     },
     "user_tz": -540
    },
    "id": "2RbzYH7kY7Jg"
   },
   "outputs": [],
   "source": [
    "# list of benchmarks for each label\n",
    "benchmark = []\n",
    "for i in range(10):\n",
    "    tmp = []\n",
    "    for j in range(len(lst[i])):\n",
    "        tmp.append(lst[i][j])\n",
    "    benchmark.append(np.mean(np.array(tmp), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "choice = []\n",
    "with open('dropdown.txt', 'r') as f:\n",
    "    for l in f:\n",
    "        choice.append(l.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1097,
     "status": "ok",
     "timestamp": 1593247688747,
     "user": {
      "displayName": "강소영",
      "photoUrl": "",
      "userId": "00381892188238952708"
     },
     "user_tz": -540
    },
    "id": "Kxdxz9M8iSPU"
   },
   "outputs": [],
   "source": [
    "# compare and contrast by tensor subtraction\n",
    "def plotCompare(feature1, feature2):\n",
    "    if feature1.shape != feature2.shape:\n",
    "        print(\"Shapes don't match\")\n",
    "        return\n",
    "\n",
    "    feature1 = K.eval(feature1)\n",
    "    feature2 = K.eval(feature2)\n",
    "    filters = feature1.shape[3]  # number of filters\n",
    "    #plt.figure(1, figsize=(20,20))\n",
    "    n_columns = 5\n",
    "    n_rows = math.ceil(filters / n_columns) + 1\n",
    "\n",
    "    for i in range(filters):\n",
    "        gap = tf.math.abs(tf.math.subtract(feature1[0,:,:,i], feature2[0,:,:,i]))\n",
    "        plt.subplot(n_rows, n_columns, i+1)\n",
    "        plt.title('Filter ' + str(i))\n",
    "        plt.imshow(gap, interpolation='nearest', cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Interactive Widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact_manual\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "903e814d3e14477a9dfe458f7d2ae2d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Image', options=('1) predicted: 3, label: 2', '4) predicted: 9, la…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact_manual\n",
    "def filterViz(Image = choice, Layer = [0, 1, 2]):\n",
    "    i = Image.split(')')\n",
    "    idx = int(i[0])\n",
    "    i = Image.split(',')\n",
    "    predicted = int(i[0][-1])\n",
    "    answer = int(i[1][-1])\n",
    "    \n",
    "    hiddens = get_hidden_layers(idx)    \n",
    "    hiddens_p = get_hidden_layers(predicted, True)\n",
    "    hiddens_a = get_hidden_layers(answer, True)\n",
    "    \n",
    "    %matplotlib inline\n",
    "    sns.set_style('darkgrid')\n",
    "    \n",
    "    fig1 = plt.figure(1)\n",
    "    fig1.suptitle(f'Predicted to be {predicted}; Answer is {answer}', fontsize=20)\n",
    "    predict(idx, True)\n",
    "    \n",
    "    fig2 = plt.figure(2, figsize=(50,20))\n",
    "    fig2.suptitle(f'Hidden layer{Layer} of the image', fontsize=50)\n",
    "    plotNNFilter(hiddens[Layer])\n",
    "\n",
    "    fig3 = plt.figure(3, figsize=(50,20))\n",
    "    fig3.suptitle(f'Hidden layer{Layer} of benchmark {predicted}', fontsize=50)\n",
    "    plotNNFilter(hiddens_p[Layer])\n",
    "    \n",
    "    fig4 = plt.figure(4, figsize=(50,20))\n",
    "    fig4.suptitle(f'Hidden layer{Layer} of benchmark {answer}', fontsize=50)\n",
    "    plotNNFilter(hiddens_a[Layer])\n",
    "    \n",
    "    fig5 = plt.figure(5, figsize=(50,20))\n",
    "    fig5.suptitle(f'Compare n Contrast with benchmark {predicted}', fontsize=50)\n",
    "    plotCompare(hiddens_p[Layer], hiddens[Layer])\n",
    "\n",
    "    fig6 = plt.figure(6, figsize=(50,20))\n",
    "    fig6.suptitle(f'Compare n Contrast with benchmark {answer}', fontsize=50)\n",
    "    plotCompare(hiddens_a[Layer], hiddens[Layer])\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNkse2p0VP1mXmijvQqu1BO",
   "collapsed_sections": [],
   "name": "mnist_keras.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
